{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28ccfe83-6b6b-4a5a-8e02-0c7f66279e7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NULLS:\n+------------------+----------+----------------+------------+---------+-------------------+-------------------+--------------------+-------------------+-------------------+--------------------+---------------------+--------------------+-------------+--------------+---------------------------+--------------+\n|imdb_name_id_nulls|name_nulls|birth_name_nulls|height_nulls|bio_nulls|birth_details_nulls|date_of_birth_nulls|place_of_birth_nulls|death_details_nulls|date_of_death_nulls|place_of_death_nulls|reason_of_death_nulls|spouses_string_nulls|spouses_nulls|divorces_nulls|spouses_with_children_nulls|children_nulls|\n+------------------+----------+----------------+------------+---------+-------------------+-------------------+--------------------+-------------------+-------------------+--------------------+---------------------+--------------------+-------------+--------------+---------------------------+--------------+\n|                 0|         0|               0|       49958|        0|                  0|                  0|                4104|              52129|              52129|               53373|                60534|               48051|            0|             0|                          0|             0|\n+------------------+----------+----------------+------------+---------+-------------------+-------------------+--------------------+-------------------+-------------------+--------------------+---------------------+--------------------+-------------+--------------+---------------------------+--------------+\n\nCLEANED NAME:\n+---------------+---------------+\n|           name|     clean_name|\n+---------------+---------------+\n|   Fred Astaire|   Fred Astaire|\n|  Lauren Bacall|  Lauren Bacall|\n|Brigitte Bardot|Brigitte Bardot|\n|   John Belushi|   John Belushi|\n| Ingmar Bergman| Ingmar Bergman|\n+---------------+---------------+\nonly showing top 5 rows\n\nEXTRACTED BIRTH YEAR:\n+-------------+----------+\n|date_of_birth|birth_year|\n+-------------+----------+\n|   1899-05-10|      1899|\n|   16.09.1924|          |\n|   28.09.1934|          |\n|   24.01.1949|          |\n|   14.07.1918|          |\n+-------------+----------+\nonly showing top 5 rows\n\nAGGREGATES:\n+-----------------+\n|     avg_children|\n+-----------------+\n|0.476577520253517|\n+-----------------+\n\n+------------+\n|max_divorces|\n+------------+\n|          12|\n+------------+\n\n+-------------------+\n|unique_birth_places|\n+-------------------+\n|              16979|\n+-------------------+\n\nEXPLODED PLACES:\n+---------------+--------------+\n|name           |exploded_place|\n+---------------+--------------+\n|Fred Astaire   |Omaha         |\n|Fred Astaire   |Nebraska      |\n|Fred Astaire   |USA           |\n|Lauren Bacall  |The Bronx     |\n|Lauren Bacall  |New York City |\n|Lauren Bacall  |New York      |\n|Lauren Bacall  |USA           |\n|Brigitte Bardot|Paris         |\n|Brigitte Bardot|France        |\n|John Belushi   |Chicago       |\n|John Belushi   |Illinois      |\n|John Belushi   |USA           |\n|Ingmar Bergman |Uppsala       |\n|Ingmar Bergman |Uppsala län   |\n|Ingmar Bergman |Sweden        |\n|Ingrid Bergman |Stockholm     |\n|Ingrid Bergman |Sweden        |\n|Humphrey Bogart|New York City |\n|Humphrey Bogart|New York      |\n|Humphrey Bogart|USA           |\n+---------------+--------------+\nonly showing top 20 rows\n\nBORN IN OMAHA?\n+-------------------+--------------------+-------------------+\n|               name|  birth_places_array|was_born_in_houston|\n+-------------------+--------------------+-------------------+\n|       Fred Astaire|[Omaha, Nebraska,...|               true|\n|      Lauren Bacall|[The Bronx, New Y...|              false|\n|    Brigitte Bardot|     [Paris, France]|              false|\n|       John Belushi|[Chicago, Illinoi...|              false|\n|     Ingmar Bergman|[Uppsala, Uppsala...|              false|\n|     Ingrid Bergman| [Stockholm, Sweden]|              false|\n|    Humphrey Bogart|[New York City, N...|              false|\n|     Richard Burton|[Pontrhydyfen, Wa...|              false|\n|       James Cagney|[New York City, N...|              false|\n|        Gary Cooper|[Helena, Montana,...|              false|\n|        Bette Davis|[Lowell, Massachu...|              false|\n|          Doris Day|[Cincinnati, Ohio...|              false|\n|Olivia de Havilland|      [Tokyo, Japan]|              false|\n|         James Dean|[Marion, Indiana,...|              false|\n|    Georges Delerue|[Roubaix, Nord, F...|              false|\n|   Marlene Dietrich|[Schöneberg, Berl...|              false|\n|       Kirk Douglas|[Amsterdam, New Y...|              false|\n|   Federico Fellini|[Rimini, Emilia-R...|              false|\n|        Henry Fonda|[Grand Island, Ne...|              false|\n|      Joan Fontaine|      [Tokyo, Japan]|              false|\n+-------------------+--------------------+-------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "filePath = \"dbfs:/FileStore/tables/Files/names.csv\"\n",
    "df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(filePath)\n",
    "\n",
    "nulls_df = df.select([\n",
    "    F.count(F.when(F.col(c).isNull(), c)).alias(f\"{c}_nulls\") for c in df.columns\n",
    "])\n",
    "\n",
    "filled_df = df.fillna({\n",
    "    \"name\": \"Unknown\",\n",
    "    \"birth_name\": \"Unknown\",\n",
    "    \"height\": 0,\n",
    "    \"bio\": \"Brak danych\",\n",
    "    \"spouses\": 0,\n",
    "    \"divorces\": 0,\n",
    "    \"spouses_with_children\": 0,\n",
    "    \"children\": 0\n",
    "})\n",
    "\n",
    "dropped_df = filled_df.drop(\"death_details\")\n",
    "\n",
    "regex_replace_df = df.withColumn(\"clean_name\", F.regexp_replace(F.col(\"name\"), \"\\\\d\", \"\"))\n",
    "\n",
    "regex_extract_df = df.withColumn(\"birth_year\", F.regexp_extract(F.col(\"date_of_birth\"), r\"^(\\d{4})\", 1))\n",
    "\n",
    "ifnull_df = df.withColumn(\"safe_height\", F.expr(\"ifnull(height, 170)\"))\n",
    "nullif_df = df.withColumn(\"name_diff\", F.expr(\"nullif(name, birth_name)\"))\n",
    "replaced_df = df.withColumn(\"updated_bio\", F.expr(\"replace(bio, 'actor', 'performer')\"))\n",
    "\n",
    "avg_children = df.select(F.avg(\"children\").alias(\"avg_children\"))\n",
    "max_divorces = df.select(F.max(\"divorces\").alias(\"max_divorces\"))\n",
    "unique_birth_places = df.select(F.countDistinct(\"place_of_birth\").alias(\"unique_birth_places\"))\n",
    "\n",
    "places_df = df.withColumn(\"birth_places_array\", F.split(F.col(\"place_of_birth\"), \", \"))\n",
    "exploded_places_df = places_df.withColumn(\"exploded_place\", F.explode(F.col(\"birth_places_array\")))\n",
    "\n",
    "contains_df = places_df.withColumn(\n",
    "    \"was_born_in_houston\", \n",
    "    F.array_contains(F.col(\"birth_places_array\"), \"Omaha\")\n",
    ")\n",
    "\n",
    "print(\"NULLS:\")\n",
    "nulls_df.show()\n",
    "\n",
    "print(\"CLEANED NAME:\")\n",
    "regex_replace_df.select(\"name\", \"clean_name\").show(5)\n",
    "\n",
    "print(\"EXTRACTED BIRTH YEAR:\")\n",
    "regex_extract_df.select(\"date_of_birth\", \"birth_year\").show(5)\n",
    "\n",
    "print(\"AGGREGATES:\")\n",
    "avg_children.show()\n",
    "max_divorces.show()\n",
    "unique_birth_places.show()\n",
    "\n",
    "print(\"EXPLODED PLACES:\")\n",
    "exploded_places_df.select(\"name\", \"exploded_place\").show(truncate=False)\n",
    "\n",
    "print(\"BORN IN OMAHA?\")\n",
    "contains_df.select(\"name\", \"birth_places_array\", \"was_born_in_houston\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aeef635f-14be-45f3-99c4-8d5e865b2b57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n|height|height_inches|\n+------+-------------+\n|   177|        69.69|\n|   174|         68.5|\n|   166|        65.35|\n|   170|        66.93|\n|   179|        70.47|\n|   178|        70.08|\n|   173|        68.11|\n|   178|        70.08|\n|   165|        64.96|\n|   191|         75.2|\n|   160|        62.99|\n|   170|        66.93|\n|   163|        64.17|\n|   173|        68.11|\n|  null|          0.0|\n|   164|        64.57|\n|   175|         68.9|\n|   182|        71.65|\n|   187|        73.62|\n|   161|        63.39|\n+------+-------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "# Standardowa funkcja UDF (korzystająca z Pythona)\n",
    "def cm_to_inches(height_cm):\n",
    "    if height_cm is None:\n",
    "        return 0.0\n",
    "    return round(height_cm * 0.393701, 2)\n",
    "\n",
    "# Rejestracja funkcji jako UDF\n",
    "cm_to_inches_udf = udf(cm_to_inches, DoubleType())\n",
    "\n",
    "# Użycie UDF w DataFrame\n",
    "df_with_inches = df.withColumn(\"height_inches\", cm_to_inches_udf(F.col(\"height\")))\n",
    "df_with_inches.select(\"height\", \"height_inches\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bdbcdb3-2d27-42d7-99db-54ea83605615",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+------------+\n|birth_name                         |last_name   |\n+-----------------------------------+------------+\n|Frederic Austerlitz Jr.            |Jr.         |\n|Betty Joan Perske                  |Perske      |\n|Brigitte Bardot                    |Bardot      |\n|John Adam Belushi                  |Belushi     |\n|Ernst Ingmar Bergman               |Bergman     |\n|Ingrid Bergman                     |Bergman     |\n|Humphrey DeForest Bogart           |Bogart      |\n|Richard Walter Jenkins             |Jenkins     |\n|James Francis Cagney               |Cagney      |\n|Frank James Cooper                 |Cooper      |\n|Ruth Elizabeth Davis               |Davis       |\n|Doris Mary Ann Kappelhoff          |Kappelhoff  |\n|Olivia Mary de Havilland           |Havilland   |\n|James Byron Dean                   |Dean        |\n|Georges Henri Jean-Baptiste Delerue|Delerue     |\n|Marie Magdalene Dietrich           |Dietrich    |\n|Issur Herschelevitch Danielovitch  |Danielovitch|\n|Federico Fellini                   |Fellini     |\n|Henry Jaynes Fonda                 |Fonda       |\n|Joan de Beauvoir de Havilland      |Havilland   |\n+-----------------------------------+------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark.sql.types import StringType\n",
    "import pandas as pd\n",
    "\n",
    "# Pandas UDF do wyciągania nazwiska z pełnego imienia\n",
    "@pandas_udf(StringType())\n",
    "def extract_last_name(birth_name: pd.Series) -> pd.Series:\n",
    "    return birth_name.fillna(\"\").apply(lambda x: x.strip().split(\" \")[-1] if x else \"Unknown\")\n",
    "\n",
    "# Użycie\n",
    "df_with_last_name = df.withColumn(\"last_name\", extract_last_name(F.col(\"birth_name\")))\n",
    "df_with_last_name.select(\"birth_name\", \"last_name\").show(truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "cw4",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}