{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63669d15-4f37-4f1f-8213-6bd0030b137f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PipelineLogger:Dane wczytane z /databricks-datasets/retail-org/customers/customers.csv, liczba rekordów: 28813\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wykonano MERGE do tabeli default.customers_clean\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# KONFIGURACJA (NO HARD-CODING)\n",
    "# -----------------------------\n",
    "dbutils.widgets.text(\"input_path\", \"/databricks-datasets/retail-org/customers/customers.csv\")\n",
    "dbutils.widgets.text(\"target_table\", \"default.customers_clean\")\n",
    "input_path = dbutils.widgets.get(\"input_path\")\n",
    "target_table = dbutils.widgets.get(\"target_table\")\n",
    "\n",
    "# -----------------------------\n",
    "# IMPORTY I LOGOWANIE\n",
    "# -----------------------------\n",
    "import logging\n",
    "from pyspark.sql.functions import col, current_timestamp\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"PipelineLogger\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1. MODUŁ - Wczytanie danych\n",
    "# -----------------------------\n",
    "def load_data(path):\n",
    "    df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(path)\n",
    "    logger.info(f\"Dane wczytane z {path}, liczba rekordów: {df.count()}\")\n",
    "    return df\n",
    "\n",
    "# -----------------------------\n",
    "# 2. MODUŁ - Walidacja danych\n",
    "# -----------------------------\n",
    "def validate_data(df):\n",
    "    assert \"customer_id\" in df.columns, \"Brakuje kolumny customer_id\"\n",
    "    assert df.filter(col(\"loyalty_segment\").isNull()).count() == 0, \"Brakuje danych w loyalty_segment\"\n",
    "    return df\n",
    "\n",
    "# -----------------------------\n",
    "# 3. MODUŁ - Transformacja\n",
    "# -----------------------------\n",
    "def transform_data(df):\n",
    "    return df.withColumn(\"processed_at\", current_timestamp())\n",
    "\n",
    "# -----------------------------\n",
    "# 4. MODUŁ - Zapis idempotentny (MERGE)\n",
    "# -----------------------------\n",
    "def write_data_merge(df, target_table):\n",
    "    from delta.tables import DeltaTable\n",
    "    from pyspark.sql.utils import AnalysisException\n",
    "\n",
    "    try:\n",
    "        delta_table = DeltaTable.forName(spark, target_table)\n",
    "        existing_columns = set(delta_table.toDF().columns)\n",
    "        incoming_columns = set(df.columns)\n",
    "\n",
    "        if existing_columns != incoming_columns:\n",
    "            print(f\"Schemat tabeli {target_table} nie pasuje. Nadpisuję tabelę.\")\n",
    "            spark.sql(f\"DROP TABLE IF EXISTS {target_table}\")\n",
    "            df.write.format(\"delta\").saveAsTable(target_table)\n",
    "        else:\n",
    "            (delta_table.alias(\"t\")\n",
    "             .merge(\n",
    "                df.alias(\"s\"),\n",
    "                \"t.customer_id = s.customer_id\"\n",
    "             )\n",
    "             .whenMatchedUpdateAll()\n",
    "             .whenNotMatchedInsertAll()\n",
    "             .execute())\n",
    "            print(f\"Wykonano MERGE do tabeli {target_table}\")\n",
    "    except AnalysisException:\n",
    "        df.write.format(\"delta\").saveAsTable(target_table)\n",
    "        print(f\"Utworzono nową tabelę {target_table}\")\n",
    "\n",
    "def deduplicate_on_key(df, key_column):\n",
    "    return df.dropDuplicates([key_column])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# PIPELINE\n",
    "# -----------------------------\n",
    "raw_df = load_data(input_path)\n",
    "valid_df = validate_data(raw_df)\n",
    "transformed_df = transform_data(valid_df)\n",
    "dedup_df = deduplicate_on_key(transformed_df, \"customer_id\")\n",
    "write_data_merge(dedup_df, target_table)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Poka_yoke",
   "widgets": {
    "input_path": {
     "currentValue": "/databricks-datasets/retail-org/customers/customers.csv",
     "nuid": "105b6c62-37e1-44d5-b6e6-6929b3e6f19d",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "/databricks-datasets/retail-org/customers/customers.csv",
      "label": null,
      "name": "input_path",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "/databricks-datasets/retail-org/customers/customers.csv",
      "label": null,
      "name": "input_path",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "target_table": {
     "currentValue": "default.customers_clean",
     "nuid": "2e48589b-4c1a-422a-975d-13fed5fd4800",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "default.customers_clean",
      "label": null,
      "name": "target_table",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "default.customers_clean",
      "label": null,
      "name": "target_table",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}